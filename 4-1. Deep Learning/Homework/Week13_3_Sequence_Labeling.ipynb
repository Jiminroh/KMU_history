{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQESSDVgMuXB",
    "outputId": "89356ed6-4124-4fff-98b3-e3915098eda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.6.0\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 388 kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 34.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.13.1\n",
      "    Uninstalling torchtext-0.13.1:\n",
      "      Successfully uninstalled torchtext-0.13.1\n",
      "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n",
      "2022-11-30 03:06:56.604220: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 18.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.8.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fZ41i4QhM7xn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BWUIRvKQNCGX"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sltV9TgaNW83"
   },
   "source": [
    "# <b>1. Torchtext로 전처리하기</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzOtQbzwPWVi"
   },
   "source": [
    "## <b>(1) Field 정의하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZONtJCByNQ7z"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True)\n",
    "UD_TAGS = data.Field(unk_token=None)\n",
    "PTB_TAGS = data.Field(unk_token=None)\n",
    "\n",
    "fields = (('text', TEXT), ('udtags',UD_TAGS), ('ptbtags', PTB_TAGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PScYV1VPcOT"
   },
   "source": [
    "## <b>(2) dataset 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G1U89ZKoad6t"
   },
   "outputs": [],
   "source": [
    "datasets.UDPOS.splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUOufpZXN6MS",
    "outputId": "d4224120-4004-4ac4-cf99-01bbec6dcd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12543\n",
      "2002\n",
      "2077\n",
      "dict_keys(['text', 'udtags', 'ptbtags'])\n",
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n",
      "29\n",
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n",
      "29\n",
      "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "trn_data, val_data, tst_data = datasets.UDPOS.splits(fields)\n",
    "print(len(trn_data))\n",
    "print(len(val_data))\n",
    "print(len(tst_data))\n",
    "print(vars(trn_data.examples[0]).keys())\n",
    "\n",
    "print(vars(trn_data.examples[0])['text'])\n",
    "print(len(vars(trn_data.examples[0])['text']))\n",
    "\n",
    "print(vars(trn_data.examples[0])['udtags']) # 우리가 사용할 label\n",
    "print(len(vars(trn_data.examples[0])['udtags']))\n",
    "\n",
    "print(vars(trn_data.examples[0])['ptbtags'])\n",
    "print(len(vars(trn_data.examples[0])['ptbtags']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0TReEo8Pm_Q"
   },
   "source": [
    "## <b>(3) 단어 집합(vocab) 만들기</b>\n",
    "- 사전 학습된 word의 embedding vector불러오기 (by glove method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY6N0Z03PB9G",
    "outputId": "4736b07e-de28-4ab9-cefb-4596e2cb100c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:17<00:00, 22447.59it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 5\n",
    "\n",
    "TEXT.build_vocab(trn_data, min_freq = MIN_FREQ, \n",
    "                 vectors='glove.6B.100d')\n",
    "UD_TAGS.build_vocab(trn_data)\n",
    "PTB_TAGS.build_vocab(trn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xx4zfDKRR8hi",
    "outputId": "dc527b6b-dd9f-4519-9ebd-1a8deab518b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 9076),\n",
      " ('.', 8640),\n",
      " (',', 7021),\n",
      " ('to', 5137),\n",
      " ('and', 5002),\n",
      " ('a', 3782),\n",
      " ('of', 3622),\n",
      " ('i', 3379),\n",
      " ('in', 3112),\n",
      " ('is', 2239),\n",
      " ('you', 2156),\n",
      " ('that', 2036),\n",
      " ('it', 1850),\n",
      " ('for', 1842),\n",
      " ('-', 1426),\n",
      " ('have', 1359),\n",
      " ('\"', 1296),\n",
      " ('on', 1273),\n",
      " ('was', 1244),\n",
      " ('with', 1216)]\n"
     ]
    }
   ],
   "source": [
    "# 상위 빈도수 20개 단어\n",
    "from pprint import pprint\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2szr4BRS6lh",
    "outputId": "2f3a2743-807f-43c7-b080-e8b8832cb82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 34781),\n",
      " ('PUNCT', 23679),\n",
      " ('VERB', 23081),\n",
      " ('PRON', 18577),\n",
      " ('ADP', 17638),\n",
      " ('DET', 16285),\n",
      " ('PROPN', 12946),\n",
      " ('ADJ', 12477),\n",
      " ('AUX', 12343),\n",
      " ('ADV', 10548),\n",
      " ('CCONJ', 6707),\n",
      " ('PART', 5567),\n",
      " ('NUM', 3999),\n",
      " ('SCONJ', 3843),\n",
      " ('X', 847),\n",
      " ('INTJ', 688),\n",
      " ('SYM', 599)]\n"
     ]
    }
   ],
   "source": [
    "# 상위 빈도순으로 udtags출력\n",
    "pprint(UD_TAGS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYwvN1CfUG3y",
    "outputId": "338fd823-d0c3-4976-f0b1-5344fc749b84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'VERB',\n",
       " 'PRON',\n",
       " 'ADP',\n",
       " 'DET',\n",
       " 'PROPN',\n",
       " 'ADJ',\n",
       " 'AUX',\n",
       " 'ADV',\n",
       " 'CCONJ',\n",
       " 'PART',\n",
       " 'NUM',\n",
       " 'SCONJ',\n",
       " 'X',\n",
       " 'INTJ',\n",
       " 'SYM']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UD_TAGS.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DonhhXjZVFAA"
   },
   "outputs": [],
   "source": [
    "def tag_percentage(tag_cnts):\n",
    "    total_cnt = sum([cnt for tag, cnt in tag_cnts])\n",
    "    tag_cnt_ratio = [(tag, cnt, cnt/total_cnt) for tag, cnt in tag_cnts]\n",
    "    return tag_cnt_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owdFLwWnVrdw",
    "outputId": "b93255aa-545c-40be-9616-a75da7ccd97e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\t34781\t17.0%\n",
      "PUNCT\t23679\t11.6%\n",
      "VERB\t23081\t11.3%\n",
      "PRON\t18577\t9.1%\n",
      "ADP\t17638\t8.6%\n",
      "DET\t16285\t8.0%\n",
      "PROPN\t12946\t6.3%\n",
      "ADJ\t12477\t6.1%\n",
      "AUX\t12343\t6.0%\n",
      "ADV\t10548\t5.2%\n",
      "CCONJ\t6707\t3.3%\n",
      "PART\t5567\t2.7%\n",
      "NUM\t3999\t2.0%\n",
      "SCONJ\t3843\t1.9%\n",
      "X\t847\t0.4%\n",
      "INTJ\t688\t0.3%\n",
      "SYM\t599\t0.3%\n"
     ]
    }
   ],
   "source": [
    "for tag, cnt, percent in tag_percentage(UD_TAGS.vocab.freqs.most_common()):\n",
    "    print(f'{tag}\\t{cnt}\\t{percent*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23tw2MSbWHqA"
   },
   "source": [
    "## <b>(4) data를 불러오기 위한 iterator 생성하기</b>\n",
    "- torchtext.data.BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKUX3BrSV7Qb"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT_RATIO = 0.25\n",
    "\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBED_DIM = 100\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "LR = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvZqNZ2xWLWn"
   },
   "outputs": [],
   "source": [
    "trn_iter, val_iter, tst_iter = data.BucketIterator.splits(datasets = (trn_data, val_data, tst_data), \n",
    "                                                          batch_size = BATCH_SIZE, device=device)\n",
    "trn_batch = next(iter(trn_iter))\n",
    "val_batch = next(iter(val_iter))\n",
    "tst_batch = next(iter(tst_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzJ8O3rWYfHx",
    "outputId": "9af634f2-7cb1-4747-a7a4-b893ac6f9b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 64])\n",
      "torch.Size([95, 64])\n",
      "torch.Size([95, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "# batch_size: [seq길이, batch_size]\n",
    "# \n",
    "print(trn_batch.text.shape)\n",
    "print(trn_batch.udtags.shape)\n",
    "print(trn_batch.ptbtags.shape)\n",
    "print(val_batch.text.shape)\n",
    "print(val_batch.udtags.shape)\n",
    "print(val_batch.ptbtags.shape)\n",
    "print(tst_batch.text.shape)\n",
    "print(tst_batch.udtags.shape)\n",
    "print(tst_batch.ptbtags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TM5XS5dIZG8v",
    "outputId": "5615d102-27a1-4017-b26b-845ccaa7c6ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0, 1906,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0, 1906,    0,  127,  141,    0,    0, 1906,    0,    0,\n",
       "            0,    0,    0,    0,  812, 1494,    0,    0,  812,    0,  812,  812,\n",
       "          439,  812,  127,    0,    0,    0,    0,    0,    0,  322,  678,    0,\n",
       "            0,  581,    0,    0,    0,    0,   37,    0,   37,   37,   37,    0,\n",
       "            0,  732,    0, 2355]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQHvKWqraYav",
    "outputId": "85f8dd2a-f03a-400c-d83d-ca3738ae768e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  7,  3, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,  3,  7,  1,\n",
       "          7,  1, 17,  3,  7,  7,  7,  7,  7,  7,  7, 10,  2,  2,  7,  7,  7,  7,\n",
       "          7,  7,  1,  7,  1,  7,  7,  7,  1,  7,  7,  1, 17,  7, 16,  7,  7,  7,\n",
       "          2, 17,  2,  2,  2, 17, 17,  7,  7,  2]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch.udtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BwUrQj_YqD-"
   },
   "source": [
    "### <b>위 과정에서 소모해버린 batch를 다시 포함시키기 위해 iter를 다시 선언할게요</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhBdpE-pWr21"
   },
   "outputs": [],
   "source": [
    "trn_iter, val_iter, tst_iter = data.BucketIterator.splits(datasets = (trn_data, val_data, tst_data), \n",
    "                                                          batch_size = BATCH_SIZE, \n",
    "                                                          shuffle=True, \n",
    "                                                          repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa7okyESa4Vb"
   },
   "source": [
    "# <b> 2. RNN model 구현하기(LSTM)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C42HUPz7ba7s"
   },
   "outputs": [],
   "source": [
    "nn.LSTM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8ZEwI8piAdo"
   },
   "source": [
    "## <b>(1) RNN기반 POSTagger정의하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocKPGwzzasi2"
   },
   "outputs": [],
   "source": [
    "class POSTagger(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, \n",
    "                 embed_dim, output_dim, bidirectional, dropout_ratio):\n",
    "        super(POSTagger, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=bidirectional, \n",
    "                            batch_first=False)\n",
    "        if bidirectional==True:\n",
    "            self.fc = nn.Linear(self.hidden_dim*2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [seq_len, batch_size]\n",
    "        x = self.embed(x)\n",
    "        # x = self.dropout(self.embed(x))\n",
    "\n",
    "        # x.shape: [seq_len, batch_size, embed_dim]\n",
    "        # h0/c0.shape: [n_direction * n_layers, batch_size, hidden_dim]\n",
    "        if self.bidirectional:\n",
    "            h0 = torch.zeros(self.n_layers*2, x.shape[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(self.n_layers*2, x.shape[1], self.hidden_dim)\n",
    "        else:\n",
    "            h0 = torch.zeros(self.n_layers, x.shape[1], self.hidden_dim)\n",
    "            c0 = torch.zeros(self.n_layers, x.shape[1], self.hidden_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # outputs.shape: [seq_len, batch_size, hidden_dim*n_direction]\n",
    "        # hidden/cell.shape: [n_direction * n_layers, batch_size, hidden_dim]\n",
    "        pred = self.fc(self.dropout(outputs))\n",
    "        return pred        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhUTuErbiE_D"
   },
   "source": [
    "## <b>(2) POSTagger클래스의 객체 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1dgb-4ShaxG"
   },
   "outputs": [],
   "source": [
    "model = POSTagger(n_layers=N_LAYERS, \n",
    "                  hidden_dim=HIDDEN_DIM, \n",
    "                  n_vocab=VOCAB_SIZE, \n",
    "                  embed_dim=EMBED_DIM, \n",
    "                  output_dim=OUTPUT_DIM, \n",
    "                  bidirectional=BIDIRECTIONAL, \n",
    "                  dropout_ratio=DROPOUT_RATIO,\n",
    "                  device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIIZsBtfgpD4"
   },
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return (sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Hpu3XWWhYwW",
    "outputId": "061b83a4-ce75-43cd-de19-e5703ade72f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027510"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIr34OUUh9OB"
   },
   "source": [
    "## <b>(3) pretrained embeddings를 불러와서 model의 embedding vector에 대입</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjp27AWkiVue",
    "outputId": "b9ba3094-b844-497f-9c82-2de0c5a3c6b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0365,  1.4937, -1.0886,  ...,  1.1405, -1.0644,  0.2250],\n",
       "        [ 1.5411, -0.1954,  0.9268,  ...,  0.9268, -0.1336, -0.0992],\n",
       "        [ 0.7603, -0.3772,  1.6935,  ...,  0.0609, -0.4518, -0.7856],\n",
       "        ...,\n",
       "        [ 0.1608, -0.1501,  0.5520,  ..., -0.7621, -0.3459,  0.2111],\n",
       "        [ 0.3467, -2.3064,  0.3042,  ..., -2.2237, -1.0584, -0.6246],\n",
       "        [-0.1133,  0.2989, -1.2837,  ..., -0.9017,  0.7505, -0.9861]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNedvdtThXzH",
    "outputId": "0c2a929c-ebb6-4b3f-ca61-c05c84f141a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1020,  0.7700,  0.1169,  ..., -0.1416, -0.1932, -0.4225],\n",
       "        [-0.0263,  0.0179, -0.5016,  ..., -0.8688,  0.9409, -0.2882],\n",
       "        [ 0.1519,  0.4712,  0.0895,  ..., -0.4702, -0.3127,  0.1078]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained vectors로 기존 모델의 embedding vectors를 덮어씌운 결과\n",
    "model.embed.weight.data.copy_(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4dbAiHEiYze",
    "outputId": "38e4b74a-455d-42ec-c2f5-29ca2b399997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1020,  0.7700,  0.1169,  ..., -0.1416, -0.1932, -0.4225],\n",
       "        [-0.0263,  0.0179, -0.5016,  ..., -0.8688,  0.9409, -0.2882],\n",
       "        [ 0.1519,  0.4712,  0.0895,  ..., -0.4702, -0.3127,  0.1078]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "786vdY3rikXc"
   },
   "source": [
    "## (4) <b> \\<unk\\>과 \\<pad\\>토큰의 인덱스 지정 및 zero vector로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqL4q_eSia_3",
    "outputId": "959c9745-1536-48b2-ecf7-befb1c283f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "print(UNK_IDX)\n",
    "print(PAD_IDX)\n",
    " # 0번 임베딩 벡터에는 0값을 채운다.\n",
    "model.embed.weight.data[UNK_IDX] = torch.zeros(EMBED_DIM)\n",
    " # 1번 임베딩 벡터에는 0값을 채운다.\n",
    "model.embed.weight.data[PAD_IDX] = torch.zeros(EMBED_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wP8kXf7jW-T"
   },
   "source": [
    "## <b>(5) optimizer 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQwhR3W1jYOY"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm_CNXWXjI9W"
   },
   "source": [
    "# <b>3. 모델 학습 및 평가 함수 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iNEaEmhjgwu"
   },
   "outputs": [],
   "source": [
    "# Padding에 대해서는 loss를 구하지 않도록\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjJUVdTqkTMl"
   },
   "source": [
    "- 위에서 미리 만들어두었던 trn_batch로 결과를 미리 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuGVLEJxjxVp",
    "outputId": "d7f9c62a-25ba-4d35-a44b-6719c4ba55d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 64])\n",
      "torch.Size([95, 64, 18])\n"
     ]
    }
   ],
   "source": [
    "pred = model(trn_batch.text)\n",
    "print(trn_batch.text.shape) # shape: [seq_len, batch_size]\n",
    "print(pred.shape) # shape: [seq_len, batch_size, output_dim(tag개수)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ud8m_z1Oj0i_",
    "outputId": "31030e03-b461-487d-caa8-eff2b619a058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 15,  2,  ...,  3,  4,  4],\n",
      "        [14,  2,  7,  ...,  4,  8,  3],\n",
      "        [ 2,  7,  0,  ...,  3,  3,  6],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 0,  0,  0,  ...,  0,  0,  0]], device='cuda:0')\n",
      "torch.Size([95, 64])\n"
     ]
    }
   ],
   "source": [
    "print(trn_batch.udtags)\n",
    "print(trn_batch.udtags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ht6yWSZDnkQR"
   },
   "source": [
    "- 아래와 같이 바로 pred와 label을 넣으면 loss가 구해지지 않습니다\n",
    "    - cross entropy를 구할 때, pred의 label로 반드시 class수가 와야합니다.\n",
    "    - seq_len도 매 배치마다 달라질 수 있습니다.\n",
    "- loss값을 쉽게 구해주기 위해 약간의 처리를 해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "bQYQ5h0km05J",
    "outputId": "5041df7d-6521-4270-8312-34cae98f21e1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b682c52b5d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [95, 18], got [95, 64]"
     ]
    }
   ],
   "source": [
    "loss_func(pred, trn_batch.udtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lu1HtPeKm-V1",
    "outputId": "e3b3c069-7f6a-4a45-c663-cc4d49472573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6080, 18])\n",
      "torch.Size([6080])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8900, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.reshape(pred, shape=(-1, pred.shape[-1]))\n",
    "print(pred.shape)\n",
    "label = torch.reshape(trn_batch.udtags, shape=(-1,))\n",
    "print(label.shape)\n",
    "loss_func(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8dgZ4cQpiE-"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    미니 배치에 대한 정확도 출력\n",
    "    \"\"\"\n",
    "\n",
    "    # get the index of the max probability\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum().item() / non_pad_elements.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anB3DBHkqNJk"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, pad_idx, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        #text.shape: [seq_len, batch_size]\n",
    "        #label.shape: [seq_len, batch_size]\n",
    "        text = batch.text.to(device)\n",
    "        label = batch.udtags.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #preds.shape: [seq_len, batch_size, output_dim(n_tags)]\n",
    "        preds = model(text)\n",
    "\n",
    "        # preds.shape: [seq_len * batch_size, output_dim]\n",
    "        # label.shape: [seq_len * batch_size, ]\n",
    "        preds = preds.view(-1, preds.shape[-1]) \n",
    "        label = label.view(-1) \n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = categorical_accuracy(preds, label, pad_idx)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9h7SZkhrPXs"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, pad_idx, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            #text.shape: [seq_len, batch_size]\n",
    "            #label.shape [seq_len, batch_size]\n",
    "            text = batch.text.to(device)\n",
    "            label = batch.udtags.to(device)\n",
    "\n",
    "            #preds.shape: [seq_len, batch_size, output_dim(n_tags)]\n",
    "            preds = model(text)\n",
    "\n",
    "            # preds.shape [seq_len * batch_size, output_dim]\n",
    "            # label.shape [seq_len * batch_size]\n",
    "            preds = preds.view(-1, preds.shape[-1])\n",
    "            label = label.view(-1)\n",
    "\n",
    "            loss = criterion(preds, label)\n",
    "\n",
    "            acc = categorical_accuracy(preds, label, pad_idx)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQJIh5bDr5BL",
    "outputId": "f20f0610-0c25-44d9-9300-65d24bad6cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.4575 | Train Acc: 86.56%\n",
      "\t Val. Loss: 0.8055 |  Val. Acc: 79.27%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.0901 | Train Acc: 97.43%\n",
      "\t Val. Loss: 0.5760 |  Val. Acc: 85.23%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.0595 | Train Acc: 98.19%\n",
      "\t Val. Loss: 0.5168 |  Val. Acc: 86.67%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.0489 | Train Acc: 98.48%\n",
      "\t Val. Loss: 0.5038 |  Val. Acc: 86.45%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.0429 | Train Acc: 98.67%\n",
      "\t Val. Loss: 0.4721 |  Val. Acc: 87.46%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.0381 | Train Acc: 98.79%\n",
      "\t Val. Loss: 0.4786 |  Val. Acc: 87.30%\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.0350 | Train Acc: 98.89%\n",
      "\t Val. Loss: 0.4614 |  Val. Acc: 87.77%\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.0302 | Train Acc: 99.05%\n",
      "\t Val. Loss: 0.4415 |  Val. Acc: 88.33%\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.0278 | Train Acc: 99.12%\n",
      "\t Val. Loss: 0.4444 |  Val. Acc: 88.29%\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.0246 | Train Acc: 99.23%\n",
      "\t Val. Loss: 0.4387 |  Val. Acc: 88.35%\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    trn_loss, trn_acc = train(model=model, iterator=trn_iter, \n",
    "                              optimizer=optimizer, criterion=loss_func, \n",
    "                              pad_idx=PAD_IDX, device=device)\n",
    "    val_loss, val_acc = evaluate(model=model, iterator=val_iter, \n",
    "                                 criterion=loss_func, pad_idx=PAD_IDX, \n",
    "                                 device=device)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {trn_loss:.4f} | Train Acc: {trn_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {val_loss:.4f} |  Val. Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaS3q5PLsgbo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
