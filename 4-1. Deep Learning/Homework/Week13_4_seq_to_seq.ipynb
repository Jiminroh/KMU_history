{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lcFU0fIVzNzI"
   },
   "outputs": [],
   "source": [
    "# Code from https://codlingual.tistory.com/91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7uUz1B-uJEm",
    "outputId": "6b1521ed-370f-4b85-af75-27c79441827a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.6.0\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 634 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.64.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.12.1+cu113)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.21.6)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 40.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (4.1.1)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.13.1\n",
      "    Uninstalling torchtext-0.13.1:\n",
      "      Successfully uninstalled torchtext-0.13.1\n",
      "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 14.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.8.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting de-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.4.0) (3.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.4.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vqw3NPXgufJi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r1sy73pSzI90"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VgGoNLhpztHg"
   },
   "outputs": [],
   "source": [
    "# 각 언어에 맞는 tokenizer 불러오기 \n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-EK7o3W-zK8X"
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    # 독일어 tokenize해서 단어들을 리스트로 만든 후 reverse \n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "    \n",
    "def tokenize_en(text):\n",
    "    # 영어 tokenize해서 단어들을 리스트로 만들기\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLBFmc5azUmN"
   },
   "source": [
    "# <b>1. Torchtext로 전처리하기</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JSbjOTFzVju"
   },
   "source": [
    "## <b>(1) Field 정의하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CTk1fk9EzRLG"
   },
   "outputs": [],
   "source": [
    "# SRC = source = input\n",
    "SRC = data.Field(tokenize = tokenize_de, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "# TRG = target = output\n",
    "TRG = data.Field(tokenize = tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar2p6Ec0zi0K"
   },
   "source": [
    "## <b>(2) dataset 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inOH0FMuzenL",
    "outputId": "24e1040c-3946-456a-a70c-c459e7892a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 5.52MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.79MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.59MB/s]\n"
     ]
    }
   ],
   "source": [
    "# exts : 어떤 언어 사용할지 명시 (input 언어를 먼저 씀)\n",
    "# fields = (입력, 출력) \n",
    "trn_data, val_data, tst_data = datasets.Multi30k.splits(exts=('.de', '.en'), \n",
    "                                                        fields=(SRC,TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6EYc5E3zo0p",
    "outputId": "0b64b275-773d-40c9-af0d-95bef06dab93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['.',\n",
      "         'büsche',\n",
      "         'vieler',\n",
      "         'nähe',\n",
      "         'der',\n",
      "         'in',\n",
      "         'freien',\n",
      "         'im',\n",
      "         'sind',\n",
      "         'männer',\n",
      "         'weiße',\n",
      "         'junge',\n",
      "         'zwei'],\n",
      " 'trg': ['two',\n",
      "         'young',\n",
      "         ',',\n",
      "         'white',\n",
      "         'males',\n",
      "         'are',\n",
      "         'outside',\n",
      "         'near',\n",
      "         'many',\n",
      "         'bushes',\n",
      "         '.']}\n"
     ]
    }
   ],
   "source": [
    "# 독일어는 단어 순서가 거꾸로...?\n",
    "from pprint import pprint\n",
    "pprint(vars(trn_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YO-5x33c0OVd"
   },
   "source": [
    "## <b>(3) 단어 집합(vocab) 만들기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6WmuthgCz4Ml"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(trn_data, min_freq=2)\n",
    "TRG.build_vocab(trn_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOqQEFYD0TWK",
    "outputId": "8fba5687-0359-4e4d-e8b0-21b3af0cd492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 28809),\n",
      " ('ein', 18851),\n",
      " ('einem', 13711),\n",
      " ('in', 11895),\n",
      " ('eine', 9909),\n",
      " (',', 8938),\n",
      " ('und', 8925),\n",
      " ('mit', 8843),\n",
      " ('auf', 8745),\n",
      " ('mann', 7805),\n",
      " ('einer', 6765),\n",
      " ('der', 4990),\n",
      " ('frau', 4186),\n",
      " ('die', 3949),\n",
      " ('zwei', 3873),\n",
      " ('einen', 3479),\n",
      " ('im', 3107),\n",
      " ('an', 3062),\n",
      " ('von', 2363),\n",
      " ('sich', 2273)]\n"
     ]
    }
   ],
   "source": [
    "pprint(SRC.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_l9adC-n0Zuj",
    "outputId": "ec68b22e-8793-4a8b-df48-16a10e33e63e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 49165),\n",
      " ('.', 27623),\n",
      " ('in', 14886),\n",
      " ('the', 10955),\n",
      " ('on', 8035),\n",
      " ('man', 7781),\n",
      " ('is', 7525),\n",
      " ('and', 7379),\n",
      " ('of', 6871),\n",
      " ('with', 6179),\n",
      " ('woman', 3973),\n",
      " (',', 3963),\n",
      " ('two', 3886),\n",
      " ('are', 3717),\n",
      " ('to', 3128),\n",
      " ('people', 3122),\n",
      " ('at', 2927),\n",
      " ('an', 2861),\n",
      " ('wearing', 2623),\n",
      " ('shirt', 2324)]\n"
     ]
    }
   ],
   "source": [
    "pprint(TRG.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm6Qfo-R0iB9"
   },
   "source": [
    "## <b>(4) data를 불러오기 위한 iterator 생성하기</b>\n",
    "- torchtext.data.BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "33xKZCby0ckd"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HIDDEN_DIM = 512\n",
    "\n",
    "ENC_EMBED_DIM = 256\n",
    "DEC_EMBED_DIM = 256\n",
    "\n",
    "N_LAYERS=2\n",
    "\n",
    "ENC_DROPOUT=0.5\n",
    "DEC_DROPOUT=0.5\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wZ8RDMf-0lNg"
   },
   "outputs": [],
   "source": [
    "trn_iter, val_iter, tst_iter = data.BucketIterator.splits(datasets = (trn_data, val_data, tst_data), \n",
    "                                                          batch_size = BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjZnGxYL2GxD"
   },
   "source": [
    "# <b> 2. seq-to-seq model 구현하기(LSTM)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppLYJFpT2bQK"
   },
   "source": [
    "## <b>(1) Encoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "giLjyN7z0nea"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(input_dim, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        # src = [src len, batch_size]\n",
    "        embedded = self.dropout(self.embed(src))\n",
    "        \n",
    "        # embedded = [src len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHjfCBTF2__V"
   },
   "source": [
    "## <b>(2) Decoder</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G7X7SYoJ28of"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(output_dim, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # Decoder에서 항상 n_directions = 1\n",
    "        # 따라서 hidden = [n layers, batch size, hid dim]\n",
    "        # context = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # input = [1, batch size]\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        # embedded = [1, batch size, emb dim]\n",
    "        embed = self.dropout(self.embed(input))\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embed, (hidden, cell))\n",
    "        \n",
    "        # output = [seq len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        # Decoder에서 항상 seq len = n directions = 1 \n",
    "        # 한 번에 한 토큰씩만 디코딩하므로 seq len = 1\n",
    "        # 따라서 output = [1, batch size, hid dim]\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # cell = [n layers, batch size, hid dim]\n",
    "        \n",
    "        # prediction = [batch size, output dim]\n",
    "        pred = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return pred, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hs3z-E7487S"
   },
   "source": [
    "## <b>(3)Seq2Seq</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cjzE_AvD4tDb"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "   def __init__(self, encoder, decoder):\n",
    "       super().__init__()\n",
    "       \n",
    "       self.encoder = encoder\n",
    "       self.decoder = decoder\n",
    "       \n",
    "       # Encoder와 Decoder의 hidden dim이 같아야 함\n",
    "       assert encoder.hidden_dim == decoder.hidden_dim\n",
    "       # Encoder와 Decoder의 layer 개수가 같아야 함\n",
    "       assert encoder.n_layers == decoder.n_layers\n",
    "       \n",
    "   def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "       # src = [src len, batch size]\n",
    "       # trg = [trg len, batch size]\n",
    "       \n",
    "       trg_len = trg.shape[0]\n",
    "       batch_size = trg.shape[1]\n",
    "       trg_vocab_size = self.decoder.output_dim\n",
    "       \n",
    "       # decoder 결과를 저장할 텐서\n",
    "       outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "       \n",
    "       # Encoder의 마지막 은닉 상태가 Decoder의 초기 은닉상태로 쓰임\n",
    "       hidden, cell = self.encoder(src)\n",
    "       \n",
    "       # Decoder에 들어갈 첫 input은 <sos> 토큰\n",
    "       input = trg[0, :]\n",
    "       \n",
    "       # target length만큼 반복\n",
    "       # range(0,trg_len)이 아니라 range(1,trg_len)인 이유 : 0번째 trg는 항상 <sos>라서 그에 대한 output도 항상 0 \n",
    "       for t in range(1, trg_len):\n",
    "           output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "           outputs[t] = output\n",
    "           \n",
    "           # random.random() : [0,1] 사이 랜덤한 숫자 \n",
    "           # 랜덤 숫자가 teacher_forcing_ratio보다 작으면 True니까 teacher_force=1\n",
    "           teacher_force = random.random() < teacher_forcing_ratio\n",
    "           \n",
    "           # 확률 가장 높게 예측한 토큰\n",
    "           top1 = output.argmax(1) \n",
    "           \n",
    "           # techer_force = 1 = True이면 trg[t]를 아니면 top1을 input으로 사용\n",
    "           input = trg[t] if teacher_force else top1\n",
    "       \n",
    "       return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-xAtZqx52eO"
   },
   "source": [
    "## <b>(4) 모델 객체 생성 및 optimizer 정의</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "uCq4Qv-p5UWJ"
   },
   "outputs": [],
   "source": [
    "enc = Encoder(input_dim=INPUT_DIM, \n",
    "              embed_dim=ENC_EMBED_DIM, \n",
    "              hidden_dim=HIDDEN_DIM, \n",
    "              n_layers=N_LAYERS, \n",
    "              dropout=ENC_DROPOUT).to(device)\n",
    "dec = Decoder(output_dim = OUTPUT_DIM, \n",
    "              embed_dim = DEC_EMBED_DIM, \n",
    "              hidden_dim=HIDDEN_DIM,\n",
    "              n_layers=N_LAYERS, \n",
    "              dropout = DEC_DROPOUT).to(device)\n",
    "model = Seq2Seq(enc, dec).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr68c_VV62q0"
   },
   "source": [
    "# <b>3. 모델 학습 및 평가 함수 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rfk4-d_36Lz7"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# <pad> 토큰의 index를 넘겨 받으면 오차 계산하지 않고 ignore하기\n",
    "# <pad> = padding\n",
    "trg_pad_idx = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = trg_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eM1VR8sj680X"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, device):\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src.to(device)\n",
    "        trg = batch.trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg).to(device)\n",
    "        \n",
    "        # trg = [trg len, batch size]\n",
    "        # output = [trg len, batch size, output dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # trg = [(trg len-1) * batch size]\n",
    "        # output = [(trg len-1) * batch size, output dim)]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 기울기 폭발 막기 위해 clip\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LGd0tCBx7Qy6"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.src.to(device)\n",
    "            trg = batch.trg.to(device)\n",
    "            \n",
    "            # teacher_forcing_ratio = 0 (아무것도 알려주면 안 됨)\n",
    "            output = model(src, trg, 0).to(device)\n",
    "            \n",
    "            # trg = [trg len, batch size]\n",
    "            # output = [trg len, batch size, output dim]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            # trg = [(trg len - 1) * batch size]\n",
    "            # output = [(trg len - 1) * batch size, output dim]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss+=loss.item()\n",
    "        \n",
    "        return epoch_loss/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEktExa17Wkg",
    "outputId": "4f9885f3-0249-4446-e128-425e97f83fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Elapsed Time: 176.19s\n",
      "\tTrain Loss: 4.8179 | Train PPL: 123.710\n",
      "\t Val. Loss: 4.7150 |  Val. PPL: 111.613\n",
      "Epoch: 02 | Elapsed Time: 175.90s\n",
      "\tTrain Loss: 4.2756 | Train PPL:  71.922\n",
      "\t Val. Loss: 4.5061 |  Val. PPL:  90.565\n",
      "Epoch: 03 | Elapsed Time: 176.21s\n",
      "\tTrain Loss: 4.0001 | Train PPL:  54.603\n",
      "\t Val. Loss: 4.3038 |  Val. PPL:  73.981\n",
      "Epoch: 04 | Elapsed Time: 175.83s\n",
      "\tTrain Loss: 3.7943 | Train PPL:  44.449\n",
      "\t Val. Loss: 4.1464 |  Val. PPL:  63.205\n",
      "Epoch: 05 | Elapsed Time: 176.03s\n",
      "\tTrain Loss: 3.6027 | Train PPL:  36.699\n",
      "\t Val. Loss: 4.0731 |  Val. PPL:  58.737\n",
      "Epoch: 06 | Elapsed Time: 174.95s\n",
      "\tTrain Loss: 3.4380 | Train PPL:  31.124\n",
      "\t Val. Loss: 3.9179 |  Val. PPL:  50.294\n",
      "Epoch: 07 | Elapsed Time: 174.96s\n",
      "\tTrain Loss: 3.3156 | Train PPL:  27.538\n",
      "\t Val. Loss: 3.8592 |  Val. PPL:  47.429\n",
      "Epoch: 08 | Elapsed Time: 175.49s\n",
      "\tTrain Loss: 3.1845 | Train PPL:  24.156\n",
      "\t Val. Loss: 3.8551 |  Val. PPL:  47.235\n",
      "Epoch: 09 | Elapsed Time: 175.12s\n",
      "\tTrain Loss: 3.0755 | Train PPL:  21.660\n",
      "\t Val. Loss: 3.7808 |  Val. PPL:  43.850\n",
      "Epoch: 10 | Elapsed Time: 176.35s\n",
      "\tTrain Loss: 2.9751 | Train PPL:  19.592\n",
      "\t Val. Loss: 3.7842 |  Val. PPL:  44.002\n"
     ]
    }
   ],
   "source": [
    "CLIP = 1\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    trn_loss = train(model, trn_iter, optimizer, criterion, CLIP, device)\n",
    "    val_loss = evaluate(model, val_iter, criterion, device)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Elapsed Time: {elapsed_time:.2f}s')\n",
    "    print(f'\\tTrain Loss: {trn_loss:.4f} | Train PPL: {math.exp(trn_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.4f} |  Val. PPL: {math.exp(val_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLsuIL-yAl_Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
