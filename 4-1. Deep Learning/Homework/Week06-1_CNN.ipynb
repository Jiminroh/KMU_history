{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed7c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65570d",
   "metadata": {},
   "source": [
    "# 연산을 수행할 device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0bf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11e90a",
   "metadata": {},
   "source": [
    "# Dataset 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30724ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(), # 이미지를 텐서로 변경하고\n",
    "                                transforms.Normalize((0.1307,), # 이미지를 0.1307, 0.3081값으로 normalize\n",
    "                                                     (0.3081,))\n",
    "                               ])\n",
    "\n",
    "trn_dset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
    "tst_dset = datasets.MNIST(root=data_path, train=False, transform=transform, download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdeefb6",
   "metadata": {},
   "source": [
    "# 모델 Class정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e09394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.fc1   = nn.Linear(7*7*128, 100, bias=True)\n",
    "        self.fc2   = nn.Linear(100, 10, bias=True)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, submodule):\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(submodule.weight)\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01)\n",
    "        if isinstance(submodule, nn.Linear): # submodule이 nn.Linear에서 생성된 객체(혹은 인스턴스이면)\n",
    "            nn.init.kaiming_normal_(submodule.weight) #해당 submodule의 weight는 He Initialization으로 초기화\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01) # 해당 submodule의 bias는 0.01로 초기화\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # (n_data, n_channel, width, height)으로 연산 결과의 크기 표기\n",
    "        x = self.conv1(x) # (batch,1,28,28) -> (batch,64,28,28)\n",
    "        x = F.relu(x)     \n",
    "        x = self.pool1(x) # (batch,64,28,28) -> (batch,64,14,14)\n",
    "        x = self.conv2(x) # (batch,64,14,14) -> (batch,128,14,14)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x) # (batch,128,14,14) -> (batch,128,7,7)\n",
    "        x = x.reshape(-1, 7*7*128)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe83305",
   "metadata": {},
   "source": [
    "# 실제 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99ba6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c938b6",
   "metadata": {},
   "source": [
    "# Optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac25cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr = 2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef304ba3",
   "metadata": {},
   "source": [
    "# DataLoader정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9655f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "trn_epochs = 50\n",
    "trn_loader = DataLoader(dataset = trn_dset, batch_size = batch_size, shuffle=True, drop_last=True)\n",
    "tst_loader = DataLoader(dataset = tst_dset, batch_size = batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4b063c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368b7c3",
   "metadata": {},
   "source": [
    "# 학습 및 Infernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe9272ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> In epoch 1 [40/234], Training Loss: 1.7279"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m y_batch_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(y_batch_prob, y_batch)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [4], line 27\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)     \n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x) \u001b[38;5;66;03m# (batch,64,28,28) -> (batch,64,14,14)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch,64,14,14) -> (batch,128,14,14)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(x) \u001b[38;5;66;03m# (batch,128,14,14) -> (batch,128,7,7)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(trn_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(trn_loader):\n",
    "        x_batch = x_batch.to(device) # 차원을 늘려줌. Tensor with (256,28,28) --> (1,256,28,28)\n",
    "#         x_batch = x_batch.reshape(1,-1,28,28).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        y_batch_prob = model(x_batch)\n",
    "        loss = F.cross_entropy(y_batch_prob, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx+1 == len(trn_loader):\n",
    "            print(f'\\r>> In epoch {epoch+1} [{batch_idx+1}/{len(trn_loader)}], Training Loss: {loss.item():.4f}', end='')\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        model.eval()\n",
    "        y_pred_list = []\n",
    "        y_real_list = []\n",
    "        tst_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(tst_loader):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_batch_prob = model(x_batch)\n",
    "                y_batch_pred = torch.argmax(y_batch_prob, axis=1)\n",
    "                loss = F.cross_entropy(y_batch_prob, y_batch, reduction='sum')\n",
    "                tst_loss += loss\n",
    "                \n",
    "                y_pred_list.append(y_batch_pred.detach().numpy())\n",
    "                y_real_list.append(y_batch.detach().numpy())\n",
    "                \n",
    "            y_real = np.concatenate([x for x in y_real_list], axis=0)\n",
    "            y_pred = np.concatenate([x for x in y_pred_list], axis=0)\n",
    "            tst_loss /= y_real.shape[0]\n",
    "            correct = np.sum(y_real == y_pred)\n",
    "            accuracy = 100*correct / len(tst_loader.dataset)\n",
    "            \n",
    "            print(f'\\t >> In epoch {epoch+1}: avg test loss={tst_loss:.4f}, accuracy={accuracy:.2f}% [{correct}/{len(tst_loader.dataset)}]')\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862733e8",
   "metadata": {},
   "source": [
    "# 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c01fef7",
   "metadata": {},
   "source": [
    "<span style = 'font-size:1.4em;line-height:1.5em'>1. 모델 class를 다음과 같이 변형하여 작성하고, 실제 모델을 만들어서 학습해봅시다.(학습 과정 자체는 오래 걸릴테니 정상적으로 돌아가는 것만 확인하고 멈추셔도 좋습니다.</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>(1) 3번째 Convolution Layer를 추가해봅시다. 3*3size의 filter의 갯수는 256개가 되도록 하며, padding=(1,1), stride=(2,2)로 정의하세요. 이 때, Convolution Layer가 끝나면, fully connected의 결과도 바뀌기 때문에 얘도 바꿔주세요. </span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>(2) Convolution연산이 끝날때마다, batchnorm을 추가해주세요. (1)에서 생성한 세번째 conv layer에 대한 BN도 생성해주세요.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac1016-8277-41ca-b0ca-611d6b476659",
   "metadata": {},
   "source": [
    "#### (1) conv layer 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52da2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.fc1   = nn.Linear(2*2*256, 100, bias=True)\n",
    "        self.fc2   = nn.Linear(100, 10, bias=True)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, submodule):\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(submodule.weight)\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01)\n",
    "        if isinstance(submodule, nn.Linear): # submodule이 nn.Linear에서 생성된 객체(혹은 인스턴스이면)\n",
    "            nn.init.kaiming_normal_(submodule.weight) #해당 submodule의 weight는 He Initialization으로 초기화\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01) # 해당 submodule의 bias는 0.01로 초기화\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # (n_data, n_channel, width, height)으로 연산 결과의 크기 표기\n",
    "        x = self.conv1(x) # (batch,1,28,28) -> (batch,64,28,28)\n",
    "        x = F.relu(x)     \n",
    "        x = self.pool1(x) # (batch,64,28,28) -> (batch,64,14,14)\n",
    "        \n",
    "        x = self.conv2(x) # (batch,64,14,14) -> (batch,128,14,14)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x) # (batch,128,14,14) -> (batch,128,7,7)\n",
    "        \n",
    "        x = self.conv3(x) # (batch,128,7,7) -> (batch,256,4,4)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x) # (batch,256,4,4) -> (batch,256,2,2)\n",
    "        \n",
    "        x = x.reshape(-1, 2*2*256)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b457d9-230f-4a2f-ab12-0f65d777611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "589a9b64-9d19-4830-bae1-919bfaf589d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f9e5c5-6219-40ec-a80a-4a276aa970d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([256, 1, 28, 28])\n",
      "output shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x_batch, y_batch) in enumerate(trn_loader):\n",
    "    x_batch = x_batch.to(device) \n",
    "    print(f'input shape: {x_batch.shape}')\n",
    "    pred = model(x_batch)\n",
    "    print(f'output shape: {pred.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b2a5d3-e789-4c60-aed5-45217d067f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> In epoch 1 [20/234], Training Loss: 2.0882"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y_batch_prob \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(y_batch_prob, y_batch)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(trn_loader):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(trn_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(trn_loader):\n",
    "        x_batch = x_batch.to(device) # 차원을 늘려줌. Tensor with (256,28,28) --> (1,256,28,28)\n",
    "#         x_batch = x_batch.reshape(1,-1,28,28).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        y_batch_prob = model(x_batch)\n",
    "        loss = F.cross_entropy(y_batch_prob, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx+1 == len(trn_loader):\n",
    "            print(f'\\r>> In epoch {epoch+1} [{batch_idx+1}/{len(trn_loader)}], Training Loss: {loss.item():.4f}', end='')\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        model.eval()\n",
    "        y_pred_list = []\n",
    "        y_real_list = []\n",
    "        tst_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(tst_loader):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_batch_prob = model(x_batch)\n",
    "                y_batch_pred = torch.argmax(y_batch_prob, axis=1)\n",
    "                loss = F.cross_entropy(y_batch_prob, y_batch, reduction='sum')\n",
    "                tst_loss += loss\n",
    "                \n",
    "                y_pred_list.append(y_batch_pred.detach().numpy())\n",
    "                y_real_list.append(y_batch.detach().numpy())\n",
    "                \n",
    "            y_real = np.concatenate([x for x in y_real_list], axis=0)\n",
    "            y_pred = np.concatenate([x for x in y_pred_list], axis=0)\n",
    "            tst_loss /= y_real.shape[0]\n",
    "            correct = np.sum(y_real == y_pred)\n",
    "            accuracy = 100*correct / len(tst_loader.dataset)\n",
    "            \n",
    "            print(f'\\t >> In epoch {epoch+1}: avg test loss={tst_loss:.4f}, accuracy={accuracy:.2f}% [{correct}/{len(tst_loader.dataset)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ad683e-10d1-47d3-9f37-2c69df1930c4",
   "metadata": {},
   "source": [
    "#### (2) batchnormalization layer 추가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ee5c1a-6322-4cab-989b-92b49e0efbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.fc1   = nn.Linear(2*2*256, 100, bias=True)\n",
    "        self.fc2   = nn.Linear(100, 10, bias=True)\n",
    "        \n",
    "        self.normal_1 = nn.BatchNorm2d(64)\n",
    "        self.normal_2 = nn.BatchNorm2d(128)\n",
    "        self.normal_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, submodule):\n",
    "        if isinstance(submodule, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(submodule.weight)\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01)\n",
    "        if isinstance(submodule, nn.Linear): # submodule이 nn.Linear에서 생성된 객체(혹은 인스턴스이면)\n",
    "            nn.init.kaiming_normal_(submodule.weight) #해당 submodule의 weight는 He Initialization으로 초기화\n",
    "            if submodule.bias is not None:\n",
    "                submodule.bias.data.fill_(0.01) # 해당 submodule의 bias는 0.01로 초기화\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # (n_data, n_channel, width, height)으로 연산 결과의 크기 표기\n",
    "        x = self.conv1(x) # (batch,1,28,28) -> (batch,64,28,28)\n",
    "        x = self.normal_1(x) # channel = 64\n",
    "        x = F.relu(x)     \n",
    "        x = self.pool1(x) # (batch,64,28,28) -> (batch,64,14,14)\n",
    "        x = self.conv2(x) # (batch,64,14,14) -> (batch,128,14,14)\n",
    "        x = self.normal_2(x) # channel = 128\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x) # (batch,128,14,14) -> (batch,128,7,7)\n",
    "        x = self.conv3(x) # (batch,128,7,7) -> (batch,256,4,4)\n",
    "        x = self.normal_3(x) # channel = 256\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x) # (batch,256,4,4) -> (batch,256,2,2)\n",
    "        x = x.reshape(-1, 2*2*256)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        out = F.softmax(x, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef444c9-7150-4158-bfd3-5c59828e645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff6d5b4-2541-4dcd-87dc-aa8fcaf04a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff5cd17d-9ddd-4447-82fa-cd2bcd16fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([256, 1, 28, 28])\n",
      "output shape: torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x_batch, y_batch) in enumerate(trn_loader):\n",
    "    x_batch = x_batch.to(device) \n",
    "    print(f'input shape: {x_batch.shape}')\n",
    "    pred = model(x_batch)\n",
    "    print(f'output shape: {pred.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48c0d956-ef88-4615-a1ad-f8d9c1996f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> In epoch 1 [20/234], Training Loss: 1.8519"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y_batch_prob \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(y_batch_prob, y_batch)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(trn_loader):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(trn_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(trn_loader):\n",
    "        x_batch = x_batch.to(device) # 차원을 늘려줌. Tensor with (256,28,28) --> (1,256,28,28)\n",
    "#         x_batch = x_batch.reshape(1,-1,28,28).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        y_batch_prob = model(x_batch)\n",
    "        loss = F.cross_entropy(y_batch_prob, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if (batch_idx + 1) % 10 == 0 or batch_idx+1 == len(trn_loader):\n",
    "            print(f'\\r>> In epoch {epoch+1} [{batch_idx+1}/{len(trn_loader)}], Training Loss: {loss.item():.4f}', end='')\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        model.eval()\n",
    "        y_pred_list = []\n",
    "        y_real_list = []\n",
    "        tst_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(tst_loader):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                y_batch_prob = model(x_batch)\n",
    "                y_batch_pred = torch.argmax(y_batch_prob, axis=1)\n",
    "                loss = F.cross_entropy(y_batch_prob, y_batch, reduction='sum')\n",
    "                tst_loss += loss\n",
    "                \n",
    "                y_pred_list.append(y_batch_pred.detach().numpy())\n",
    "                y_real_list.append(y_batch.detach().numpy())\n",
    "                \n",
    "            y_real = np.concatenate([x for x in y_real_list], axis=0)\n",
    "            y_pred = np.concatenate([x for x in y_pred_list], axis=0)\n",
    "            tst_loss /= y_real.shape[0]\n",
    "            correct = np.sum(y_real == y_pred)\n",
    "            accuracy = 100*correct / len(tst_loader.dataset)\n",
    "            \n",
    "            print(f'\\t >> In epoch {epoch+1}: avg test loss={tst_loss:.4f}, accuracy={accuracy:.2f}% [{correct}/{len(tst_loader.dataset)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7c6f5-84ff-4fa6-a3b0-27a2b7993a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
