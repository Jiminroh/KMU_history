{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr821iOFwxdx"
   },
   "source": [
    "# <b>1. 환경설정하기</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cW_XV6ZA5Ky"
   },
   "source": [
    "- **Convolutional neural network(CNN)**를 사용하여 감정 분석을 할 예정입니다. \n",
    "- [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) paper의 model을 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jo0FRMpHqOjP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m573.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torchtext==0.6.0) (1.12.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torchtext==0.6.0) (1.23.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torchtext==0.6.0) (4.63.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torchtext==0.6.0) (2.28.1)\n",
      "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from requests->torchtext==0.6.0) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages (from torch->torchtext==0.6.0) (4.4.0)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.97 torchtext-0.6.0\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch/bin/python: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OBSj469eAEcv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EEgMRR1-UEzN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 2D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
       "can be precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
       "\n",
       "\n",
       "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
       "width in pixels.\n",
       "\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of padding applied to the input. It\n",
       "  can be either a string {'valid', 'same'} or a tuple of ints giving the\n",
       "  amount of implicit padding applied on both sides.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the à trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters (of size\n",
       "      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
       "\n",
       "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
       "\n",
       "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
       "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
       "      and the second `int` for the width dimension\n",
       "\n",
       "Note:\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
       "    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
       "\n",
       "Note:\n",
       "    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
       "    the input so the output has the shape as the input. However, this mode\n",
       "    doesn't support any stride values other than 1.\n",
       "\n",
       "Note:\n",
       "    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int, tuple or str, optional): Padding added to all four sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
       "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
       "\n",
       "      .. math::\n",
       "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
       "\n",
       "      .. math::\n",
       "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
       "        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``,\n",
       "        then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> # With square kernels and equal stride\n",
       "    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
       "    >>> # non-square kernels and unequal stride and with padding\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
       "    >>> # non-square kernels and unequal stride and with padding and dilation\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
       "    >>> input = torch.randn(20, 16, 50, 100)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     LazyConv2d, Conv2d, ConvBn2d, Conv2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7JZZc9zIAI5p"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMUg-7Gbw9dp"
   },
   "source": [
    "# <b>2. torchtext로 전처리하기</b>\n",
    "- data는 IMDB dataset을 사용하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement sapcy (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for sapcy\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sapcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zt2VeH6lAdXB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install SpaCy. See the docs at https://spacy.io for more information.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m TEXT \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtokenizer_language\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msequential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m LABEL \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mLabelField(sequential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      7\u001b[0m                         batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      8\u001b[0m                         dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torchtext/data/field.py:163\u001b[0m, in \u001b[0;36mField.__init__\u001b[0;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# store params to construct tokenizer for serialization\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_args \u001b[38;5;241m=\u001b[39m (tokenize, tokenizer_language)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_lengths \u001b[38;5;241m=\u001b[39m include_lengths\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.8/site-packages/torchtext/data/utils.py:113\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(tokenizer, language)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m    114\u001b[0m         spacy \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(language)\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m partial(_spacy_tokenize, spacy\u001b[38;5;241m=\u001b[39mspacy)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(tokenize='spacy', \n",
    "                  tokenizer_language = 'en_core_web_sm', \n",
    "                  sequential=True, \n",
    "                  batch_first=True, \n",
    "                  lower=True)\n",
    "LABEL = data.LabelField(sequential=False, \n",
    "                        batch_first=True, \n",
    "                        dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0brEaltymYD"
   },
   "source": [
    "## <b>(2) data로드 및 분할하기</b>\n",
    "- torchtext.datasets으로 IMDB dataset을 다운로드 받고, train, test로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_MU3tUqym8R",
    "outputId": "0c0bde35-3592-4ed2-ff1a-6e482062eeae"
   },
   "outputs": [],
   "source": [
    "trn_dset, tst_dset = datasets.IMDB.splits(TEXT, LABEL)\n",
    "trn_dset, val_dset = trn_dset.split(random_state = random.seed(seed), \n",
    "                                    split_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyIYLzJ-ysQ2",
    "outputId": "336e6408-2965-4f82-fb8e-3a7cc380710f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_dset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrn_dset\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_dset))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tst_dset))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trn_dset' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(trn_dset))\n",
    "print(len(val_dset))\n",
    "print(len(tst_dset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDPaAspWy0DH"
   },
   "source": [
    "## <b>(3) 단어 집합(vocab) 만들기\n",
    "- glove.6B.100의 학습된 임베딩 벡터를 사용\n",
    "    - (glove도 word2vec처럼 일종의 임베딩 방법론이다 라는 정도만 알고 넘어갑시다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMrBi81Oysl9",
    "outputId": "db8897c8-3fe9-4df0-fb62-add040ecd5d8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m MAX_VOCAB_SIZE\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mTEXT\u001b[49m\u001b[38;5;241m.\u001b[39mbuild_vocab(trn_dset, \n\u001b[1;32m      3\u001b[0m                  max_size \u001b[38;5;241m=\u001b[39m MAX_VOCAB_SIZE,\n\u001b[1;32m      4\u001b[0m                  vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglove.6B.100d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# 기존에 학습된 100차원의 벡터를 갖고오고\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                  unk_init \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39mnormal_) \u001b[38;5;66;03m# glove에서 학습되지 않은 벡터는 임의로 생성\u001b[39;00m\n\u001b[1;32m      6\u001b[0m LABEL\u001b[38;5;241m.\u001b[39mbuild_vocab(trn_dset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE=25000\n",
    "TEXT.build_vocab(trn_dset, \n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = 'glove.6B.100d', # 기존에 학습된 100차원의 벡터를 갖고오고\n",
    "                 unk_init = torch.Tensor.normal_) # glove에서 학습되지 않은 벡터는 임의로 생성\n",
    "LABEL.build_vocab(trn_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKmMga2Tznw3",
    "outputId": "8f846747-b0cc-42e6-c34f-891501d5b8a8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique tokens in TEXT vocabulary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(TEXT\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique tokens in LABEL vocabulary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(LABEL\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RuPuBEo0vcM",
    "outputId": "23908211-0dc5-4ccc-89a0-a1d590c34a00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fb959185f90>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'the': 2,\n",
       "             ',': 3,\n",
       "             '.': 4,\n",
       "             'and': 5,\n",
       "             'a': 6,\n",
       "             'of': 7,\n",
       "             'to': 8,\n",
       "             'is': 9,\n",
       "             'it': 10,\n",
       "             'in': 11,\n",
       "             'i': 12,\n",
       "             'this': 13,\n",
       "             'that': 14,\n",
       "             '\"': 15,\n",
       "             \"'s\": 16,\n",
       "             '-': 17,\n",
       "             '/><br': 18,\n",
       "             'was': 19,\n",
       "             'as': 20,\n",
       "             'for': 21,\n",
       "             'with': 22,\n",
       "             'movie': 23,\n",
       "             'but': 24,\n",
       "             'film': 25,\n",
       "             'you': 26,\n",
       "             'on': 27,\n",
       "             '(': 28,\n",
       "             \"n't\": 29,\n",
       "             ')': 30,\n",
       "             'not': 31,\n",
       "             'are': 32,\n",
       "             'he': 33,\n",
       "             'his': 34,\n",
       "             'have': 35,\n",
       "             'be': 36,\n",
       "             'one': 37,\n",
       "             'all': 38,\n",
       "             'at': 39,\n",
       "             'they': 40,\n",
       "             'by': 41,\n",
       "             '!': 42,\n",
       "             'an': 43,\n",
       "             'who': 44,\n",
       "             'from': 45,\n",
       "             'like': 46,\n",
       "             'so': 47,\n",
       "             'her': 48,\n",
       "             'or': 49,\n",
       "             'there': 50,\n",
       "             'just': 51,\n",
       "             'about': 52,\n",
       "             'do': 53,\n",
       "             'has': 54,\n",
       "             'out': 55,\n",
       "             \"'\": 56,\n",
       "             'if': 57,\n",
       "             'what': 58,\n",
       "             'some': 59,\n",
       "             'good': 60,\n",
       "             '?': 61,\n",
       "             'more': 62,\n",
       "             'she': 63,\n",
       "             'very': 64,\n",
       "             'when': 65,\n",
       "             'would': 66,\n",
       "             'up': 67,\n",
       "             'no': 68,\n",
       "             'even': 69,\n",
       "             'time': 70,\n",
       "             'can': 71,\n",
       "             'which': 72,\n",
       "             'my': 73,\n",
       "             'only': 74,\n",
       "             'really': 75,\n",
       "             'story': 76,\n",
       "             'had': 77,\n",
       "             'see': 78,\n",
       "             'their': 79,\n",
       "             'were': 80,\n",
       "             'we': 81,\n",
       "             'did': 82,\n",
       "             'me': 83,\n",
       "             'does': 84,\n",
       "             'well': 85,\n",
       "             'than': 86,\n",
       "             'much': 87,\n",
       "             '...': 88,\n",
       "             'could': 89,\n",
       "             'been': 90,\n",
       "             'get': 91,\n",
       "             'bad': 92,\n",
       "             'will': 93,\n",
       "             'people': 94,\n",
       "             ':': 95,\n",
       "             'also': 96,\n",
       "             'because': 97,\n",
       "             'into': 98,\n",
       "             'other': 99,\n",
       "             'great': 100,\n",
       "             'how': 101,\n",
       "             'first': 102,\n",
       "             'most': 103,\n",
       "             'him': 104,\n",
       "             'made': 105,\n",
       "             'its': 106,\n",
       "             'make': 107,\n",
       "             'then': 108,\n",
       "             'way': 109,\n",
       "             'too': 110,\n",
       "             'them': 111,\n",
       "             'any': 112,\n",
       "             '<': 113,\n",
       "             '/>the': 114,\n",
       "             'after': 115,\n",
       "             'br': 116,\n",
       "             'movies': 117,\n",
       "             'think': 118,\n",
       "             'characters': 119,\n",
       "             'character': 120,\n",
       "             'two': 121,\n",
       "             'watch': 122,\n",
       "             'films': 123,\n",
       "             'many': 124,\n",
       "             'seen': 125,\n",
       "             'being': 126,\n",
       "             ';': 127,\n",
       "             'plot': 128,\n",
       "             'never': 129,\n",
       "             'life': 130,\n",
       "             'little': 131,\n",
       "             'love': 132,\n",
       "             'where': 133,\n",
       "             'acting': 134,\n",
       "             'over': 135,\n",
       "             'best': 136,\n",
       "             'show': 137,\n",
       "             'know': 138,\n",
       "             'off': 139,\n",
       "             'man': 140,\n",
       "             'ever': 141,\n",
       "             'your': 142,\n",
       "             'better': 143,\n",
       "             'still': 144,\n",
       "             'end': 145,\n",
       "             'here': 146,\n",
       "             'say': 147,\n",
       "             'should': 148,\n",
       "             '*': 149,\n",
       "             'scene': 150,\n",
       "             'these': 151,\n",
       "             'scenes': 152,\n",
       "             'go': 153,\n",
       "             'such': 154,\n",
       "             'why': 155,\n",
       "             'while': 156,\n",
       "             \"'ve\": 157,\n",
       "             'back': 158,\n",
       "             'something': 159,\n",
       "             'through': 160,\n",
       "             '/': 161,\n",
       "             'real': 162,\n",
       "             'those': 163,\n",
       "             'old': 164,\n",
       "             'watching': 165,\n",
       "             'years': 166,\n",
       "             \"'m\": 167,\n",
       "             'thing': 168,\n",
       "             'though': 169,\n",
       "             'actors': 170,\n",
       "             'new': 171,\n",
       "             'director': 172,\n",
       "             'now': 173,\n",
       "             'work': 174,\n",
       "             'makes': 175,\n",
       "             'nothing': 176,\n",
       "             'actually': 177,\n",
       "             'before': 178,\n",
       "             'funny': 179,\n",
       "             '--': 180,\n",
       "             'find': 181,\n",
       "             'another': 182,\n",
       "             'few': 183,\n",
       "             'look': 184,\n",
       "             'going': 185,\n",
       "             'part': 186,\n",
       "             'same': 187,\n",
       "             'every': 188,\n",
       "             'lot': 189,\n",
       "             'again': 190,\n",
       "             'cast': 191,\n",
       "             '/>i': 192,\n",
       "             'ca': 193,\n",
       "             'want': 194,\n",
       "             'world': 195,\n",
       "             'us': 196,\n",
       "             'quite': 197,\n",
       "             'got': 198,\n",
       "             \"'re\": 199,\n",
       "             'down': 200,\n",
       "             'pretty': 201,\n",
       "             '&': 202,\n",
       "             'young': 203,\n",
       "             'seems': 204,\n",
       "             'things': 205,\n",
       "             'around': 206,\n",
       "             'fact': 207,\n",
       "             'horror': 208,\n",
       "             'take': 209,\n",
       "             'thought': 210,\n",
       "             'big': 211,\n",
       "             'between': 212,\n",
       "             'enough': 213,\n",
       "             'may': 214,\n",
       "             'give': 215,\n",
       "             'original': 216,\n",
       "             'long': 217,\n",
       "             'both': 218,\n",
       "             'however': 219,\n",
       "             'own': 220,\n",
       "             'series': 221,\n",
       "             'action': 222,\n",
       "             'always': 223,\n",
       "             'must': 224,\n",
       "             'right': 225,\n",
       "             'without': 226,\n",
       "             'gets': 227,\n",
       "             'family': 228,\n",
       "             'saw': 229,\n",
       "             'role': 230,\n",
       "             'comedy': 231,\n",
       "             'almost': 232,\n",
       "             'times': 233,\n",
       "             'point': 234,\n",
       "             'come': 235,\n",
       "             'whole': 236,\n",
       "             'interesting': 237,\n",
       "             'least': 238,\n",
       "             'bit': 239,\n",
       "             'guy': 240,\n",
       "             'done': 241,\n",
       "             'music': 242,\n",
       "             'anything': 243,\n",
       "             'script': 244,\n",
       "             'far': 245,\n",
       "             'last': 246,\n",
       "             'might': 247,\n",
       "             'making': 248,\n",
       "             'minutes': 249,\n",
       "             'feel': 250,\n",
       "             'since': 251,\n",
       "             'probably': 252,\n",
       "             'performance': 253,\n",
       "             'woman': 254,\n",
       "             'am': 255,\n",
       "             'girl': 256,\n",
       "             'kind': 257,\n",
       "             'worst': 258,\n",
       "             'rather': 259,\n",
       "             'tv': 260,\n",
       "             \"'ll\": 261,\n",
       "             'yet': 262,\n",
       "             'away': 263,\n",
       "             'day': 264,\n",
       "             'hard': 265,\n",
       "             'sure': 266,\n",
       "             'fun': 267,\n",
       "             'found': 268,\n",
       "             'played': 269,\n",
       "             'each': 270,\n",
       "             'anyone': 271,\n",
       "             'having': 272,\n",
       "             'our': 273,\n",
       "             'especially': 274,\n",
       "             'believe': 275,\n",
       "             'course': 276,\n",
       "             'trying': 277,\n",
       "             'looking': 278,\n",
       "             'comes': 279,\n",
       "             'goes': 280,\n",
       "             'although': 281,\n",
       "             'book': 282,\n",
       "             'screen': 283,\n",
       "             'set': 284,\n",
       "             'different': 285,\n",
       "             'put': 286,\n",
       "             'actor': 287,\n",
       "             'looks': 288,\n",
       "             'place': 289,\n",
       "             'year': 290,\n",
       "             'ending': 291,\n",
       "             'worth': 292,\n",
       "             'shows': 293,\n",
       "             'three': 294,\n",
       "             'someone': 295,\n",
       "             'dvd': 296,\n",
       "             'money': 297,\n",
       "             \"'d\": 298,\n",
       "             'let': 299,\n",
       "             'sense': 300,\n",
       "             '/>this': 301,\n",
       "             'reason': 302,\n",
       "             '10': 303,\n",
       "             'job': 304,\n",
       "             'once': 305,\n",
       "             'true': 306,\n",
       "             'plays': 307,\n",
       "             'maybe': 308,\n",
       "             'everything': 309,\n",
       "             'takes': 310,\n",
       "             'watched': 311,\n",
       "             'main': 312,\n",
       "             'seem': 313,\n",
       "             'american': 314,\n",
       "             'everyone': 315,\n",
       "             'together': 316,\n",
       "             'effects': 317,\n",
       "             'play': 318,\n",
       "             '2': 319,\n",
       "             'later': 320,\n",
       "             'said': 321,\n",
       "             'beautiful': 322,\n",
       "             'wife': 323,\n",
       "             'high': 324,\n",
       "             'left': 325,\n",
       "             'during': 326,\n",
       "             'john': 327,\n",
       "             'instead': 328,\n",
       "             'night': 329,\n",
       "             'house': 330,\n",
       "             'himself': 331,\n",
       "             'version': 332,\n",
       "             'audience': 333,\n",
       "             'half': 334,\n",
       "             'seeing': 335,\n",
       "             'special': 336,\n",
       "             'excellent': 337,\n",
       "             'nice': 338,\n",
       "             'father': 339,\n",
       "             'black': 340,\n",
       "             'shot': 341,\n",
       "             'star': 342,\n",
       "             'simply': 343,\n",
       "             'war': 344,\n",
       "             'idea': 345,\n",
       "             'read': 346,\n",
       "             'less': 347,\n",
       "             'else': 348,\n",
       "             'mind': 349,\n",
       "             'fan': 350,\n",
       "             'second': 351,\n",
       "             'men': 352,\n",
       "             'hollywood': 353,\n",
       "             'help': 354,\n",
       "             'used': 355,\n",
       "             'completely': 356,\n",
       "             'try': 357,\n",
       "             'top': 358,\n",
       "             'short': 359,\n",
       "             'dead': 360,\n",
       "             'poor': 361,\n",
       "             'home': 362,\n",
       "             'classic': 363,\n",
       "             'line': 364,\n",
       "             'death': 365,\n",
       "             'need': 366,\n",
       "             'either': 367,\n",
       "             'kids': 368,\n",
       "             'given': 369,\n",
       "             'budget': 370,\n",
       "             'women': 371,\n",
       "             'use': 372,\n",
       "             'until': 373,\n",
       "             'full': 374,\n",
       "             'low': 375,\n",
       "             'wrong': 376,\n",
       "             'performances': 377,\n",
       "             'production': 378,\n",
       "             'boring': 379,\n",
       "             'friends': 380,\n",
       "             'camera': 381,\n",
       "             'rest': 382,\n",
       "             'truly': 383,\n",
       "             'tell': 384,\n",
       "             'enjoy': 385,\n",
       "             'remember': 386,\n",
       "             'couple': 387,\n",
       "             'along': 388,\n",
       "             'stars': 389,\n",
       "             'mean': 390,\n",
       "             'video': 391,\n",
       "             'small': 392,\n",
       "             'stupid': 393,\n",
       "             'sex': 394,\n",
       "             'start': 395,\n",
       "             'awful': 396,\n",
       "             '/>it': 397,\n",
       "             'came': 398,\n",
       "             'wonderful': 399,\n",
       "             'recommend': 400,\n",
       "             'next': 401,\n",
       "             'understand': 402,\n",
       "             '..': 403,\n",
       "             'early': 404,\n",
       "             'episode': 405,\n",
       "             'moments': 406,\n",
       "             'perhaps': 407,\n",
       "             'playing': 408,\n",
       "             'face': 409,\n",
       "             'getting': 410,\n",
       "             'school': 411,\n",
       "             'terrible': 412,\n",
       "             'human': 413,\n",
       "             'definitely': 414,\n",
       "             'name': 415,\n",
       "             'written': 416,\n",
       "             'perfect': 417,\n",
       "             'often': 418,\n",
       "             'gives': 419,\n",
       "             'doing': 420,\n",
       "             'keep': 421,\n",
       "             'person': 422,\n",
       "             'style': 423,\n",
       "             'others': 424,\n",
       "             'felt': 425,\n",
       "             'boy': 426,\n",
       "             'white': 427,\n",
       "             'lines': 428,\n",
       "             'become': 429,\n",
       "             'live': 430,\n",
       "             'supposed': 431,\n",
       "             'lost': 432,\n",
       "             'liked': 433,\n",
       "             'itself': 434,\n",
       "             'piece': 435,\n",
       "             'case': 436,\n",
       "             'dialogue': 437,\n",
       "             'sort': 438,\n",
       "             'head': 439,\n",
       "             'mother': 440,\n",
       "             'went': 441,\n",
       "             'certainly': 442,\n",
       "             'absolutely': 443,\n",
       "             'killer': 444,\n",
       "             'children': 445,\n",
       "             'against': 446,\n",
       "             'called': 447,\n",
       "             'several': 448,\n",
       "             'friend': 449,\n",
       "             'finally': 450,\n",
       "             'picture': 451,\n",
       "             'problem': 452,\n",
       "             'worse': 453,\n",
       "             'entire': 454,\n",
       "             'evil': 455,\n",
       "             'hope': 456,\n",
       "             'waste': 457,\n",
       "             'loved': 458,\n",
       "             'title': 459,\n",
       "             'yes': 460,\n",
       "             'based': 461,\n",
       "             'care': 462,\n",
       "             'cinema': 463,\n",
       "             'entertaining': 464,\n",
       "             'laugh': 465,\n",
       "             'under': 466,\n",
       "             'drama': 467,\n",
       "             'dark': 468,\n",
       "             'seemed': 469,\n",
       "             'becomes': 470,\n",
       "             'fans': 471,\n",
       "             '3': 472,\n",
       "             'already': 473,\n",
       "             'beginning': 474,\n",
       "             'direction': 475,\n",
       "             'lives': 476,\n",
       "             'wanted': 477,\n",
       "             'example': 478,\n",
       "             '\\x96': 479,\n",
       "             'turn': 480,\n",
       "             'michael': 481,\n",
       "             'son': 482,\n",
       "             'child': 483,\n",
       "             'oh': 484,\n",
       "             'wo': 485,\n",
       "             'heart': 486,\n",
       "             'throughout': 487,\n",
       "             'fine': 488,\n",
       "             'sound': 489,\n",
       "             'totally': 490,\n",
       "             'guess': 491,\n",
       "             'lead': 492,\n",
       "             '<br': 493,\n",
       "             'final': 494,\n",
       "             'wants': 495,\n",
       "             'game': 496,\n",
       "             'side': 497,\n",
       "             'close': 498,\n",
       "             'guys': 499,\n",
       "             'behind': 500,\n",
       "             'amazing': 501,\n",
       "             'writing': 502,\n",
       "             'turns': 503,\n",
       "             'history': 504,\n",
       "             'quality': 505,\n",
       "             '1': 506,\n",
       "             'humor': 507,\n",
       "             'despite': 508,\n",
       "             'favorite': 509,\n",
       "             'past': 510,\n",
       "             'enjoyed': 511,\n",
       "             'today': 512,\n",
       "             'works': 513,\n",
       "             'town': 514,\n",
       "             'kill': 515,\n",
       "             'able': 516,\n",
       "             'art': 517,\n",
       "             'unfortunately': 518,\n",
       "             'days': 519,\n",
       "             'run': 520,\n",
       "             'tries': 521,\n",
       "             'hand': 522,\n",
       "             'viewer': 523,\n",
       "             'actress': 524,\n",
       "             '>': 525,\n",
       "             'kid': 526,\n",
       "             'city': 527,\n",
       "             'horrible': 528,\n",
       "             'blood': 529,\n",
       "             'car': 530,\n",
       "             'genre': 531,\n",
       "             'hour': 532,\n",
       "             'girls': 533,\n",
       "             'gave': 534,\n",
       "             'parts': 535,\n",
       "             'act': 536,\n",
       "             'self': 537,\n",
       "             'starts': 538,\n",
       "             'soon': 539,\n",
       "             'eyes': 540,\n",
       "             'themselves': 541,\n",
       "             'flick': 542,\n",
       "             'sometimes': 543,\n",
       "             'directed': 544,\n",
       "             '....': 545,\n",
       "             'late': 546,\n",
       "             'brilliant': 547,\n",
       "             'god': 548,\n",
       "             'thinking': 549,\n",
       "             'voice': 550,\n",
       "             'decent': 551,\n",
       "             'expect': 552,\n",
       "             'feeling': 553,\n",
       "             'writer': 554,\n",
       "             'slow': 555,\n",
       "             'fight': 556,\n",
       "             'obviously': 557,\n",
       "             'stories': 558,\n",
       "             'etc': 559,\n",
       "             'took': 560,\n",
       "             'strong': 561,\n",
       "             'leave': 562,\n",
       "             'matter': 563,\n",
       "             'except': 564,\n",
       "             'age': 565,\n",
       "             'daughter': 566,\n",
       "             'highly': 567,\n",
       "             'type': 568,\n",
       "             'brother': 569,\n",
       "             'heard': 570,\n",
       "             'stuff': 571,\n",
       "             'particularly': 572,\n",
       "             'involved': 573,\n",
       "             'mr.': 574,\n",
       "             'police': 575,\n",
       "             'overall': 576,\n",
       "             'myself': 577,\n",
       "             'roles': 578,\n",
       "             'happens': 579,\n",
       "             'including': 580,\n",
       "             'known': 581,\n",
       "             'moment': 582,\n",
       "             'murder': 583,\n",
       "             'stop': 584,\n",
       "             'lack': 585,\n",
       "             'hit': 586,\n",
       "             'violence': 587,\n",
       "             'killed': 588,\n",
       "             'happened': 589,\n",
       "             'extremely': 590,\n",
       "             'obvious': 591,\n",
       "             'attempt': 592,\n",
       "             'cut': 593,\n",
       "             'gore': 594,\n",
       "             'says': 595,\n",
       "             'told': 596,\n",
       "             'complete': 597,\n",
       "             'chance': 598,\n",
       "             'hell': 599,\n",
       "             'living': 600,\n",
       "             'group': 601,\n",
       "             'king': 602,\n",
       "             'james': 603,\n",
       "             'hero': 604,\n",
       "             'wonder': 605,\n",
       "             'alone': 606,\n",
       "             'experience': 607,\n",
       "             'coming': 608,\n",
       "             'looked': 609,\n",
       "             'number': 610,\n",
       "             'shown': 611,\n",
       "             'score': 612,\n",
       "             'running': 613,\n",
       "             'interest': 614,\n",
       "             'taken': 615,\n",
       "             'simple': 616,\n",
       "             'serious': 617,\n",
       "             'musical': 618,\n",
       "             'sad': 619,\n",
       "             'happen': 620,\n",
       "             'exactly': 621,\n",
       "             'husband': 622,\n",
       "             'started': 623,\n",
       "             '/>in': 624,\n",
       "             'novel': 625,\n",
       "             'usually': 626,\n",
       "             'save': 627,\n",
       "             'none': 628,\n",
       "             'song': 629,\n",
       "             'hours': 630,\n",
       "             'ago': 631,\n",
       "             '/>there': 632,\n",
       "             'middle': 633,\n",
       "             'relationship': 634,\n",
       "             'ends': 635,\n",
       "             'opening': 636,\n",
       "             'across': 637,\n",
       "             'english': 638,\n",
       "             'usual': 639,\n",
       "             'whose': 640,\n",
       "             'cinematography': 641,\n",
       "             'david': 642,\n",
       "             'happy': 643,\n",
       "             'reality': 644,\n",
       "             'jokes': 645,\n",
       "             'yourself': 646,\n",
       "             'hilarious': 647,\n",
       "             'released': 648,\n",
       "             'crap': 649,\n",
       "             'wish': 650,\n",
       "             'career': 651,\n",
       "             'scary': 652,\n",
       "             'annoying': 653,\n",
       "             'cool': 654,\n",
       "             'taking': 655,\n",
       "             'view': 656,\n",
       "             'huge': 657,\n",
       "             'robert': 658,\n",
       "             'ridiculous': 659,\n",
       "             'order': 660,\n",
       "             'body': 661,\n",
       "             'female': 662,\n",
       "             'finds': 663,\n",
       "             'please': 664,\n",
       "             'modern': 665,\n",
       "             'somewhat': 666,\n",
       "             'change': 667,\n",
       "             'ones': 668,\n",
       "             'saying': 669,\n",
       "             'mostly': 670,\n",
       "             'opinion': 671,\n",
       "             'major': 672,\n",
       "             'supporting': 673,\n",
       "             '/>if': 674,\n",
       "             'documentary': 675,\n",
       "             'light': 676,\n",
       "             'power': 677,\n",
       "             'single': 678,\n",
       "             'talking': 679,\n",
       "             'five': 680,\n",
       "             'room': 681,\n",
       "             'seriously': 682,\n",
       "             'level': 683,\n",
       "             'possible': 684,\n",
       "             'important': 685,\n",
       "             'shots': 686,\n",
       "             'turned': 687,\n",
       "             'b': 688,\n",
       "             'episodes': 689,\n",
       "             'songs': 690,\n",
       "             'word': 691,\n",
       "             'class': 692,\n",
       "             'jack': 693,\n",
       "             '5': 694,\n",
       "             'due': 695,\n",
       "             'knows': 696,\n",
       "             'four': 697,\n",
       "             'strange': 698,\n",
       "             'ok': 699,\n",
       "             'call': 700,\n",
       "             'comic': 701,\n",
       "             'country': 702,\n",
       "             'events': 703,\n",
       "             'thriller': 704,\n",
       "             'attention': 705,\n",
       "             'knew': 706,\n",
       "             'earth': 707,\n",
       "             'non': 708,\n",
       "             'british': 709,\n",
       "             'tells': 710,\n",
       "             'easily': 711,\n",
       "             'cheap': 712,\n",
       "             'bring': 713,\n",
       "             'local': 714,\n",
       "             'basically': 715,\n",
       "             'apparently': 716,\n",
       "             'clearly': 717,\n",
       "             'silly': 718,\n",
       "             'talent': 719,\n",
       "             'anyway': 720,\n",
       "             'television': 721,\n",
       "             'disappointed': 722,\n",
       "             '4': 723,\n",
       "             'future': 724,\n",
       "             'falls': 725,\n",
       "             'paul': 726,\n",
       "             'words': 727,\n",
       "             'george': 728,\n",
       "             'miss': 729,\n",
       "             'needs': 730,\n",
       "             'sequence': 731,\n",
       "             'sets': 732,\n",
       "             'appears': 733,\n",
       "             'fast': 734,\n",
       "             'problems': 735,\n",
       "             'upon': 736,\n",
       "             'it.<br': 737,\n",
       "             'rock': 738,\n",
       "             'straight': 739,\n",
       "             'moving': 740,\n",
       "             'romantic': 741,\n",
       "             'rating': 742,\n",
       "             'similar': 743,\n",
       "             'enjoyable': 744,\n",
       "             'oscar': 745,\n",
       "             'near': 746,\n",
       "             'theater': 747,\n",
       "             'mystery': 748,\n",
       "             'entertainment': 749,\n",
       "             'giving': 750,\n",
       "             '/>but': 751,\n",
       "             'animation': 752,\n",
       "             'whether': 753,\n",
       "             'beyond': 754,\n",
       "             'predictable': 755,\n",
       "             'stand': 756,\n",
       "             'nearly': 757,\n",
       "             'above': 758,\n",
       "             'easy': 759,\n",
       "             'named': 760,\n",
       "             'talk': 761,\n",
       "             'team': 762,\n",
       "             'within': 763,\n",
       "             'richard': 764,\n",
       "             'ten': 765,\n",
       "             'bunch': 766,\n",
       "             'lady': 767,\n",
       "             'feels': 768,\n",
       "             'message': 769,\n",
       "             'review': 770,\n",
       "             'using': 771,\n",
       "             'points': 772,\n",
       "             'minute': 773,\n",
       "             'red': 774,\n",
       "             'theme': 775,\n",
       "             'york': 776,\n",
       "             'lee': 777,\n",
       "             'tale': 778,\n",
       "             'sister': 779,\n",
       "             'fantastic': 780,\n",
       "             'working': 781,\n",
       "             'effort': 782,\n",
       "             'mention': 783,\n",
       "             'release': 784,\n",
       "             'eye': 785,\n",
       "             'sequel': 786,\n",
       "             'surprised': 787,\n",
       "             'dull': 788,\n",
       "             'herself': 789,\n",
       "             'french': 790,\n",
       "             'hate': 791,\n",
       "             'clear': 792,\n",
       "             'feature': 793,\n",
       "             'add': 794,\n",
       "             'showing': 795,\n",
       "             'begins': 796,\n",
       "             'elements': 797,\n",
       "             'fall': 798,\n",
       "             'typical': 799,\n",
       "             'storyline': 800,\n",
       "             'among': 801,\n",
       "             'comments': 802,\n",
       "             'form': 803,\n",
       "             're': 804,\n",
       "             'stay': 805,\n",
       "             'greatest': 806,\n",
       "             'ways': 807,\n",
       "             'peter': 808,\n",
       "             'weak': 809,\n",
       "             'famous': 810,\n",
       "             'dance': 811,\n",
       "             'tried': 812,\n",
       "             'lots': 813,\n",
       "             'season': 814,\n",
       "             'actual': 815,\n",
       "             'buy': 816,\n",
       "             'dialog': 817,\n",
       "             'soundtrack': 818,\n",
       "             'zombie': 819,\n",
       "             'kept': 820,\n",
       "             'editing': 821,\n",
       "             '/>and': 822,\n",
       "             'brought': 823,\n",
       "             'die': 824,\n",
       "             'somehow': 825,\n",
       "             'space': 826,\n",
       "             'doubt': 827,\n",
       "             'follow': 828,\n",
       "             'means': 829,\n",
       "             'gone': 830,\n",
       "             'certain': 831,\n",
       "             'leads': 832,\n",
       "             'de': 833,\n",
       "             'filmed': 834,\n",
       "             'atmosphere': 835,\n",
       "             'possibly': 836,\n",
       "             'tom': 837,\n",
       "             'wait': 838,\n",
       "             'check': 839,\n",
       "             'particular': 840,\n",
       "             'disney': 841,\n",
       "             'figure': 842,\n",
       "             'lame': 843,\n",
       "             'realistic': 844,\n",
       "             '$': 845,\n",
       "             'parents': 846,\n",
       "             'film.<br': 847,\n",
       "             'sorry': 848,\n",
       "             'suspense': 849,\n",
       "             'sexual': 850,\n",
       "             'material': 851,\n",
       "             'poorly': 852,\n",
       "             'general': 853,\n",
       "             'period': 854,\n",
       "             'viewers': 855,\n",
       "             'movie.<br': 856,\n",
       "             'crime': 857,\n",
       "             'eventually': 858,\n",
       "             'baby': 859,\n",
       "             'average': 860,\n",
       "             'deal': 861,\n",
       "             'move': 862,\n",
       "             'viewing': 863,\n",
       "             'learn': 864,\n",
       "             'stage': 865,\n",
       "             'third': 866,\n",
       "             'premise': 867,\n",
       "             'became': 868,\n",
       "             '/>as': 869,\n",
       "             'difficult': 870,\n",
       "             'expected': 871,\n",
       "             'imagine': 872,\n",
       "             'sequences': 873,\n",
       "             'reviews': 874,\n",
       "             'japanese': 875,\n",
       "             'free': 876,\n",
       "             'sit': 877,\n",
       "             'surprise': 878,\n",
       "             'street': 879,\n",
       "             'whatever': 880,\n",
       "             'decided': 881,\n",
       "             'forget': 882,\n",
       "             'indeed': 883,\n",
       "             'rent': 884,\n",
       "             'screenplay': 885,\n",
       "             '/>a': 886,\n",
       "             'romance': 887,\n",
       "             'hear': 888,\n",
       "             'america': 889,\n",
       "             'male': 890,\n",
       "             'subject': 891,\n",
       "             'meets': 892,\n",
       "             'superb': 893,\n",
       "             'avoid': 894,\n",
       "             'question': 895,\n",
       "             'dog': 896,\n",
       "             'killing': 897,\n",
       "             'meet': 898,\n",
       "             'truth': 899,\n",
       "             'write': 900,\n",
       "             'nor': 901,\n",
       "             'nature': 902,\n",
       "             's': 903,\n",
       "             '20': 904,\n",
       "             'reading': 905,\n",
       "             'badly': 906,\n",
       "             'believable': 907,\n",
       "             'forced': 908,\n",
       "             'realize': 909,\n",
       "             'open': 910,\n",
       "             'directors': 911,\n",
       "             'beauty': 912,\n",
       "             'leaves': 913,\n",
       "             'note': 914,\n",
       "             'crazy': 915,\n",
       "             'joe': 916,\n",
       "             'memorable': 917,\n",
       "             'fi': 918,\n",
       "             'older': 919,\n",
       "             'emotional': 920,\n",
       "             'sci': 921,\n",
       "             'directing': 922,\n",
       "             'earlier': 923,\n",
       "             'hot': 924,\n",
       "             'jane': 925,\n",
       "             'deep': 926,\n",
       "             'needed': 927,\n",
       "             'begin': 928,\n",
       "             'shame': 929,\n",
       "             'christmas': 930,\n",
       "             'dream': 931,\n",
       "             'footage': 932,\n",
       "             'acted': 933,\n",
       "             'situation': 934,\n",
       "             'credits': 935,\n",
       "             'keeps': 936,\n",
       "             'dramatic': 937,\n",
       "             'okay': 938,\n",
       "             'otherwise': 939,\n",
       "             'rate': 940,\n",
       "             'unless': 941,\n",
       "             'whom': 942,\n",
       "             'worked': 943,\n",
       "             'creepy': 944,\n",
       "             'fantasy': 945,\n",
       "             'forward': 946,\n",
       "             'weird': 947,\n",
       "             'imdb': 948,\n",
       "             'interested': 949,\n",
       "             'towards': 950,\n",
       "             'total': 951,\n",
       "             'ask': 952,\n",
       "             'features': 953,\n",
       "             'perfectly': 954,\n",
       "             'previous': 955,\n",
       "             'brings': 956,\n",
       "             'hands': 957,\n",
       "             'personal': 958,\n",
       "             'writers': 959,\n",
       "             'box': 960,\n",
       "             'cheesy': 961,\n",
       "             'development': 962,\n",
       "             'comment': 963,\n",
       "             'laughs': 964,\n",
       "             'appear': 965,\n",
       "             'cop': 966,\n",
       "             'leading': 967,\n",
       "             'sounds': 968,\n",
       "             'monster': 969,\n",
       "             'plenty': 970,\n",
       "             'setting': 971,\n",
       "             'casting': 972,\n",
       "             'fighting': 973,\n",
       "             'mark': 974,\n",
       "             'pay': 975,\n",
       "             'create': 976,\n",
       "             'air': 977,\n",
       "             'dumb': 978,\n",
       "             'girlfriend': 979,\n",
       "             'telling': 980,\n",
       "             'unique': 981,\n",
       "             'ben': 982,\n",
       "             'mess': 983,\n",
       "             'return': 984,\n",
       "             'society': 985,\n",
       "             'break': 986,\n",
       "             'gay': 987,\n",
       "             'remake': 988,\n",
       "             'meant': 989,\n",
       "             'social': 990,\n",
       "             'boys': 991,\n",
       "             'admit': 992,\n",
       "             'background': 993,\n",
       "             'hardly': 994,\n",
       "             'incredibly': 995,\n",
       "             'doctor': 996,\n",
       "             'plus': 997,\n",
       "             'quickly': 998,\n",
       "             'portrayed': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxi7RQDc0_yD"
   },
   "source": [
    "## <b>(4) data를 불러오기 위한 iterator 생성하기</b>\n",
    "- torchtext.data.BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3ZOauMb03zh"
   },
   "outputs": [],
   "source": [
    "# Embedding vector관련\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBED_DIM = 100\n",
    "\n",
    "# CNN구조 관련\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "N_CLASSES = 2\n",
    "DROPOUT_RATIO = 0.3\n",
    "\n",
    "# Train관련\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95aAAfKW1GDt"
   },
   "outputs": [],
   "source": [
    "trn_iter, val_iter, tst_iter = data.BucketIterator.splits(datasets = (trn_dset, val_dset, tst_dset), \n",
    "                                                          batch_size = BATCH_SIZE, \n",
    "                                                          shuffle=True, \n",
    "                                                          repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjXdifpV2CNo"
   },
   "source": [
    "# <b> 3. CNN model 구현하기</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HVQE7tz_Qi3"
   },
   "source": [
    "## <b>(1) model class 구현하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vlJuWFLF1tkr"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_vocab, embed_dim, n_filters, filter_sizes, output_dim, dropout_ratio, pad_idx):\n",
    "        super(CNN, self).__init__()\n",
    "        assert len(filter_sizes) == 3\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim, padding_idx=pad_idx)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels = n_filters, \n",
    "                               kernel_size=(filter_sizes[0], embed_dim))\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=n_filters, \n",
    "                               kernel_size=(filter_sizes[1], embed_dim))\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, \n",
    "                               out_channels=n_filters, \n",
    "                               kernel_size=(filter_sizes[2], embed_dim))\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text size: [batch_size, sentence_len]\n",
    "        embed = self.embed(text) # embed size: [batch_size, sentence_len, embed_dim]\n",
    "        embed = embed.unsqueeze(1) # embed_size: [batch_size, 1, sentence_len, embed_dim]\n",
    "\n",
    "        # conv(embed) size: (batch_size, n_filters, sentence_len-filter_size+1, 1)\n",
    "        # squeezed size: (batch_size, n_filters, sentence_len-flter_size+1)\n",
    "        conv_result1 = F.relu(self.conv1(embed).squeeze(3))\n",
    "        conv_result2 = F.relu(self.conv2(embed).squeeze(3))\n",
    "        conv_result3 = F.relu(self.conv3(embed).squeeze(3))\n",
    "\n",
    "        # pool_result size: (batch_size, n_filters, 1)\n",
    "        # squeezed size: (batch_size, n_filters)\n",
    "        pool_result1 = F.max_pool1d(conv_result1, conv_result1.shape[2]).squeeze(2)\n",
    "        pool_result2 = F.max_pool1d(conv_result2, conv_result2.shape[2]).squeeze(2)\n",
    "        pool_result3 = F.max_pool1d(conv_result3, conv_result3.shape[2]).squeeze(2)\n",
    "\n",
    "        # cat size: (batch_size, n_filters * len(filter_size))\n",
    "        cat = torch.cat((pool_result1, pool_result2, pool_result3), dim=1)\n",
    "        cat = self.dropout(cat)\n",
    "\n",
    "        return self.fc(cat)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zONQoB6t_adN"
   },
   "source": [
    "## <b>(2) 모델 객체 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXQNi-nI5wuk"
   },
   "outputs": [],
   "source": [
    "model = CNN(n_vocab=VOCAB_SIZE, \n",
    "            embed_dim=EMBED_DIM, \n",
    "            n_filters=N_FILTERS, \n",
    "            filter_sizes=FILTER_SIZES, \n",
    "            output_dim=N_CLASSES, \n",
    "            dropout_ratio=DROPOUT_RATIO, \n",
    "            pad_idx=PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5okBwTy3_fdM"
   },
   "source": [
    "## <b>(3) pretrained embeddings를 불러와서 model의 embedding vector에 대입</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMCaBcGe-54Z"
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDfVCXjP_ucr",
    "outputId": "615c8542-afe6-4646-e501-784b272a9f6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
       "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.4209,  0.9235,  0.1985,  ..., -0.7646,  0.1018,  0.3782],\n",
       "        [ 0.1707,  0.2843, -0.0560,  ...,  0.0990, -0.2200,  0.2100],\n",
       "        [ 0.1654,  0.0713, -0.0237,  ..., -0.4641,  0.7009,  0.6931]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--w3XpZD_v1b",
    "outputId": "5e3515e8-628c-460a-d195-f9235ef3f917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c455fxCN_-BH",
    "outputId": "72a15e6c-c6ff-4f7e-998b-8e7de32651a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5798, -0.9582, -0.3302,  ..., -0.3455,  0.4224, -1.3401],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4076,  1.2967,  0.3911,  ...,  0.5054,  0.3263,  0.9035],\n",
       "        ...,\n",
       "        [ 0.1310, -0.6473,  0.0078,  ..., -0.9512,  0.2684,  0.4572],\n",
       "        [ 0.3971,  0.8289, -1.8827,  ..., -0.4697, -2.7504,  1.1220],\n",
       "        [ 0.3028,  0.8413, -0.0300,  ..., -0.9295,  0.1378, -0.3617]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 model의 embedding vectors\n",
    "model.embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwbuvY90ATvE",
    "outputId": "13908728-62fb-4f5e-b7dc-fd903b9ab2e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAW8mfhbAJ4N",
    "outputId": "96d2b630-ec8f-48a4-a992-2c30a0c7ba85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
       "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.4209,  0.9235,  0.1985,  ..., -0.7646,  0.1018,  0.3782],\n",
       "        [ 0.1707,  0.2843, -0.0560,  ...,  0.0990, -0.2200,  0.2100],\n",
       "        [ 0.1654,  0.0713, -0.0237,  ..., -0.4641,  0.7009,  0.6931]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretrained vectors로 기존 모델의 embedding vectors를 덮어씌운 결과\n",
    "model.embed.weight.data.copy_(pretrained_embeddings)\n",
    "model.embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdpY0E17AgKO",
    "outputId": "31b20447-5a92-4a0f-e64d-cc4da1783b22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unknown(UNK) 토큰과 padding<PAD> token은 embedding weight를 0으로 초기화\n",
    "# PAD_IDX=1(이미 위에서 구했음)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "UNK_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCQpm1qeA13S"
   },
   "outputs": [],
   "source": [
    "model.embed.weight.data[UNK_IDX] = torch.zeros(EMBED_DIM)\n",
    "model.embed.weight.data[PAD_IDX] = torch.zeros(EMBED_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-F7qG5xzBYr-"
   },
   "source": [
    "## <b>(4) optimizer 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3E6lnfUECK0q"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHpjas96CQWf"
   },
   "source": [
    "# <b>4. 모델 학습 및 평가 함수 생성하기</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-NfCUTdBIQt"
   },
   "outputs": [],
   "source": [
    "def train(model, opt, data_iterator):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        x, y = batch.text.to(device), batch.label.to(device)\n",
    "        opt.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-q-2wpweB4sK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_iterator):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for _, batch in enumerate(data_iterator):\n",
    "        x, y = batch.text.to(device), batch.label.to(device)\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (output.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(data_iterator.dataset)\n",
    "    total_loss /= size\n",
    "    accuracy = 100*corrects / size\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "mKEsXI-9CB5K",
    "outputId": "cdcfdc11-a502-410a-ae0b-d16905555472"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-a54767d52b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-4453ae31b7fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, data_iterator)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-941a675d1538>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mconv_result1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mconv_result2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mconv_result3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pool_result size: (batch_size, n_filters, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, trn_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(f\"[Epoch: {epoch}] val loss: {val_loss:.2f} | val accuracy: {val_accuracy:.2f}\")\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/cnn_txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIgN2121CIvq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
